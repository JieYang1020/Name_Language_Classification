{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 3138.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\valid.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 2506.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 11081.83it/s]\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 8, 128])\n",
      "0.580975353717804\n",
      "torch.Size([200, 8, 128])\n",
      "0.7275846004486084\n",
      "torch.Size([200, 1, 128])\n",
      "0.007897138595581055\n",
      "torch.Size([200, 8, 128])\n",
      "1.2558563947677612\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors\n",
    "from torch.nn import init\n",
    "from tqdm import tqdm\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "\n",
    "tokenize = lambda x: x.split()\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenize, lower=True, fix_length=200)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "train_path  = r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\train.csv'\n",
    "test_path = r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\test.csv'\n",
    "valid_path = r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\valid.csv'\n",
    "\n",
    "\n",
    "# 定义Dataset\n",
    "class MyDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, path, text_field, label_field, test=False, aug=False, **kwargs):\n",
    "        fields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"comment_text\", text_field), (\"toxic\", label_field)]\n",
    "        examples = []\n",
    "        csv_data = pd.read_csv(path, engine = 'python')\n",
    "        print('read data from {}'.format(path))\n",
    "        if test:\n",
    "            # 如果为测试集，则不加载label\n",
    "            for text in tqdm(csv_data['comment_text']):\n",
    "                examples.append(data.Example.fromlist([None, text, None], fields))\n",
    "        else:\n",
    "            for text, label in tqdm(zip(csv_data['comment_text'], csv_data['toxic'])):\n",
    "                if aug:\n",
    "                    # do augmentation\n",
    "                    rate = random.random()\n",
    "                    if rate > 0.5:\n",
    "                        text = self.dropout(text)\n",
    "                    else:\n",
    "                        text = self.shuffle(text)\n",
    "                # Example: Defines a single training or test example.Stores each column of the example as an attribute.\n",
    "                examples.append(data.Example.fromlist([None, text, label], fields))\n",
    "        # 之前是一些预处理操作，此处调用super调用父类构造方法，产生标准Dataset\n",
    "        # super(MyDataset, self).__init__(examples, fields, **kwargs)\n",
    "        super(MyDataset, self).__init__(examples, fields)\n",
    "\n",
    "    def shuffle(self, text):\n",
    "        text = np.random.permutation(text.strip().split())\n",
    "        return ' '.join(text)\n",
    "\n",
    "    def dropout(self, text, p=0.5):\n",
    "        # random delete some text\n",
    "        text = text.strip().split()\n",
    "        len_ = len(text)\n",
    "        indexs = np.random.choice(len_, int(len_ * p))\n",
    "        for i in indexs:\n",
    "            text[i] = ''\n",
    "        return ' '.join(text)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, weight_matrix):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(len(TEXT.vocab), 300)  # embedding之后的shape: torch.Size([200, 8, 300])\n",
    "        # 若使用预训练的词向量，需在此处指定预训练的权重\n",
    "#         embeddings.weight.data.copy_(weight_matrix)\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=1)  # torch.Size([200, 8, 128])\n",
    "        self.decoder = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out = self.lstm(embeds)[0]  # lstm_out:200x8x128\n",
    "        print(lstm_out.shape)\n",
    "        # 取最后一个时间步\n",
    "        final = lstm_out[-1]  # 8*128\n",
    "        y = self.decoder(final)  # 8*2 \n",
    "        return y\n",
    "\n",
    "\n",
    "def data_iter(train_path, valid_path, test_path, TEXT, LABEL):\n",
    "    train = MyDataset(train_path, text_field=TEXT, label_field=LABEL, test=False, aug=1)\n",
    "    valid = MyDataset(valid_path, text_field=TEXT, label_field=LABEL, test=False, aug=1)\n",
    "    # 因为test没有label,需要指定label_field为None\n",
    "    test = MyDataset(test_path, text_field=TEXT, label_field=None, test=True, aug=1)\n",
    "    TEXT.build_vocab(train)\n",
    "    weight_matrix = TEXT.vocab.vectors\n",
    "    # 若只针对训练集构造迭代器\n",
    "    # train_iter = data.BucketIterator(dataset=train, batch_size=8, shuffle=True, sort_within_batch=False, repeat=False)\n",
    "    train_iter, val_iter = BucketIterator.splits(\n",
    "            (train, valid), # 构建数据集所需的数据集\n",
    "            batch_sizes=(8, 8),\n",
    "            # 如果使用gpu，此处将-1更换为GPU的编号\n",
    "            device=-1,\n",
    "            # the BucketIterator needs to be told what function it should use to group the data.\n",
    "            sort_key=lambda x: len(x.comment_text),\n",
    "            sort_within_batch=False,\n",
    "            repeat=False\n",
    "    )\n",
    "    test_iter = Iterator(test, batch_size=8, device=-1, sort=False, sort_within_batch=False, repeat=False)\n",
    "    return train_iter, val_iter, test_iter, weight_matrix\n",
    "\n",
    "def main():\n",
    "    train_iter, val_iter, test_iter, weight_matrix = data_iter(train_path, valid_path, test_path, TEXT, LABEL)\n",
    "    model = LSTM(weight_matrix)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "    loss_funtion = F.cross_entropy\n",
    "\n",
    "    for epoch, batch in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        predicted = model(batch.comment_text)\n",
    "        loss = loss_funtion(predicted, batch.toxic)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
