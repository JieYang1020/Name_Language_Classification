{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-40747658a2a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         self.register_buffer(\"buffer\", torch.randn([2,3]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-40747658a2a0>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvari\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         self.register_buffer(\"buffer\", torch.randn([2,3]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv2 = nn.Linear(1, 2)\n",
    "        self.vari = Variable(torch.rand([1]))\n",
    "        self.par = nn.Parameter(torch.rand([1]))\n",
    "#         self.register_buffer(\"buffer\", torch.randn([2,3]))\n",
    "model = Model()\n",
    "print(model.state_dict().keys())\n",
    "print(Variable(torch.rand([1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1   A   B\n",
      "0   K0  A0  B0\n",
      "1   K1  A1  B1\n",
      "  key1   C\n",
      "0   K0  C0\n",
      "1   K1  C1\n",
      "2   K1  C2\n",
      "3   K2  C3\n",
      "  key1   A   B   C\n",
      "0   K0  A0  B0  C0\n",
      "1   K1  A1  B1  C1\n",
      "2   K1  A1  B1  C2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "left = pd.DataFrame({'key1': [ 'K0', 'K1'],\n",
    "                     'A': ['A0', 'A1'],\n",
    "                      'B': ['B0', 'B1']})\n",
    " \n",
    "right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3']})\n",
    "result = pd.merge(left, right, on=['key1'])\n",
    "print(left)\n",
    "print(right)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 1])\n",
      "torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "#[64, 1, 19, 300]\n",
    "input = Variable(torch.randn(64, 19, 1))\n",
    "hidden = Variable(torch.randn(64, 128, 19))\n",
    "attn_weights = torch.bmm(hidden, input)\n",
    "print(attn_weights.size())\n",
    "print(attn_weights.squeeze(2).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128, 19])\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.randn(19, 64, 128))\n",
    "print(a.permute(1,2,0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16, 19, 300])\n",
      "torch.Size([64, 16, 9, 149])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(64, 16, 19, 300)\n",
    "m = nn.MaxPool2d(3, stride = 2)\n",
    "output = m(a)\n",
    "print(a.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16, 298])\n",
      "torch.Size([64, 4, 298])\n",
      "torch.Size([64, 38, 298])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1)\n",
    "x = torch.randn(64, 16, 298)\n",
    "y = torch.randn(64, 4, 298)\n",
    "q = torch.randn(64, 18, 298)\n",
    "a = torch.cat((x,y,q),1)\n",
    "# q = torch.randn(64, 18, 298)\n",
    "# d = torch.cat((z, q), 1)\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 18])\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(64, 58))\n",
    "m = nn.Linear(58, 18)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 64, 300])\n",
      "torch.Size([19, 32, 149])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv1d(64, 32, 3, stride=2)\n",
    "input = Variable(torch.randn(19, 64, 300))\n",
    "output = m(input)\n",
    "print(input.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 149])\n",
      "torch.Size([10, 9536])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv1d(19, 10, 3, stride=2)\n",
    "input = Variable(torch.randn(64, 19, 300))\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "output = output.view(output.size(1), -1) \n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "torch.manual_seed(1)\n",
    "x = torch.randn(64, 16, 298)\n",
    "y = torch.randn(64, 4, 298)\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "z = torch.cat((x, y), 1)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "te1 = pd.Series([None, None, 1])\n",
    "if pd.isnull(te1).all():\n",
    "    print(\"-----\")\n",
    "else:\n",
    "    print(\"22222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c2963c0b6c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mh0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         func = self._backend.RNN(\n\u001b[0;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    139\u001b[0m             raise RuntimeError(\n\u001b[0;32m    140\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m--> 141\u001b[1;33m                     fn.input_size, input.size(-1)))\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_input_packed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fn' is not defined"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = Variable(torch.randn(6, 1, 57))\n",
    "h0 = Variable(torch.randn(2, 1, 128))\n",
    "output, hn = rnn(input, h0)\n",
    "print(input.size())\n",
    "print(h0.size())\n",
    "print(output.size())\n",
    "print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.Series([1234567], dtype = 'object')\n",
    "b = '123456789'\n",
    "print(b[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(1, 20, 5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(20, 64, 5)),\n",
    "    ('relu2', nn.ReLU())\n",
    "]))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 17])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "test1 = nn.Conv1d(256, 100, 2, stride = 2)\n",
    "input = Variable(torch.randn(32, 256, 35))\n",
    "output = test1(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-9469c57b791a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0munpermuted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpermuted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = np.array([[[1,2,3],[4,5,6]]])\n",
    "unpermuted = torch.tensor(a)\n",
    "print(unpermuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-9c39076963cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0munpermuted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpermuted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpermuted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munpermuted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "a=np.array([[[1,2,3],[4,5,6]]])\n",
    "unpermuted=torch.tensor(a)\n",
    "print(unpermuted.size())\n",
    "permuted=unpermuted.permute(2,0,1)\n",
    "print(permuted.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= torch.Size([1, 6, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "x = torch.Tensor([1, 10, 100, 1000, 10000, 100000]).view(1, 2, -1, 1, 1)\n",
    "x = Variable(x)\n",
    "conv = nn.Conv3d(in_channels = 2, \n",
    "                 out_channels = 6,\n",
    "                kernel_size = (2,1,1),\n",
    "                stride = 1,\n",
    "                padding = 0,\n",
    "                dilation = 1,\n",
    "                groups = 1)\n",
    "conv.weight.data = torch.from_numpy(np.ones(24, dtype = np.float32).reshape(6,2,2,1,1))\n",
    "output = conv(x)\n",
    "print('output=',output.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-79-4cb74a561b3f>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-79-4cb74a561b3f>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    if os.path.exists(config.embedding_path) and config.is_training and config.is_pretrain\u001b[0m\n\u001b[1;37m                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.is_training = True\n",
    "        self.dropout_rate = config.dropout_rate\n",
    "        self.num_class = config.num_class\n",
    "        self.use_element = config.use_element\n",
    "        self.config = config\n",
    "        self.embedding = nn.Embedding(num_embeddings = config.vocab_size,\n",
    "                                     embedding_dim = config.embedding_size)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(nn.conv1d(in_channels = config.embedding_size,\n",
    "                                   out_channels = config.feature_size,\n",
    "                                   kernel_size = h),\n",
    "                         nn.ReLU(),\n",
    "                         nn.MaxPool1d(kernel_size = config.max_text_len - h + 1))\n",
    "                for h in config.window_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(in_features = config.feature_size*len(config.window_size),\n",
    "                           out_features = config.num_class)\n",
    "        if os.path.exists(config.embedding_path) and config.is_training and config.is_pretrain\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 20])\n"
     ]
    }
   ],
   "source": [
    "m = nn.MaxPool1d(4, stride = 4)\n",
    "input = Variable(torch.randn(20, 16, 80))\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 24, 43, 15])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "m = nn.MaxPool3d((3, 2, 2), stride = (2, 1, 2))\n",
    "input = Variable(torch.randn(20, 16, 50, 44, 31))\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 24, 43, 15])\n"
     ]
    }
   ],
   "source": [
    "m = nn.AvgPool3d((3, 2, 2), stride= (2, 1, 2))\n",
    "input = Variable(torch.randn(20, 16, 50, 44, 31))\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.7088\n",
      "-1.2258\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "Variable containing:\n",
      "-0.5078\n",
      "-0.7065\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "Variable containing:\n",
      "-0.0709\n",
      "-0.1226\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.ELU()\n",
    "input = Variable(torch.randn(2))\n",
    "m2 = nn.LeakyReLU(0.1)\n",
    "print(input)\n",
    "print(m(input))\n",
    "print(m2(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision.models\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "alexnet = models.alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "m = nn.BatchNorm2d(100, affine = False)\n",
    "input = Variable(torch.randn(20, 100, 35, 45))\n",
    "output = m(input)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.5508e-01  1.2024e+00  9.0714e-02  ...   4.3879e-01 -6.4861e-01  1.8239e+00\n",
      "  2.4332e-01  1.4943e-01 -1.4312e-01  ...  -8.5186e-01  1.3448e-01  1.0761e+00\n",
      "  1.0236e+00  4.5084e-01  1.5970e+00  ...   1.3010e-01 -2.6436e-01  6.4666e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.5620e-01 -9.7404e-01 -5.1149e-01  ...  -9.8248e-02  6.6779e-02 -9.7873e-01\n",
      "  9.9393e-01  8.8882e-01 -8.8929e-02  ...   3.3905e-01  4.6745e-02 -7.3732e-01\n",
      " -1.5146e+00  1.5441e+00  1.1564e-01  ...  -2.9459e-01  9.4695e-02  9.1730e-01\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  6.8980e-01 -2.2348e+00 -1.6898e+00  ...  -3.4044e-01  6.9312e-01 -1.2642e+00\n",
      " -1.4089e+00 -7.9613e-01 -5.1653e-01  ...  -7.1590e-01  1.3530e-01 -3.3573e-01\n",
      " -1.0113e+00  2.6025e-01  6.5954e-01  ...   1.0002e+00 -9.5642e-01 -5.0022e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.6597e-01 -8.0133e-01  7.3856e-01  ...   1.8079e+00  1.2864e+00  8.8952e-01\n",
      "  3.3302e-01 -4.5143e-01  1.8142e-01  ...  -5.9416e-01  7.5626e-01  2.3326e-01\n",
      "  1.8880e-01 -1.3344e+00  3.7721e-01  ...  -7.4569e-01 -1.2895e+00  2.6405e+00\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  2.2926e+00  1.0254e-01 -1.1623e+00  ...   4.5461e-01 -6.1433e-01 -1.4625e+00\n",
      "  8.8576e-01  6.1187e-01 -2.2616e-01  ...   1.3056e-01  2.1855e-01  1.2414e+00\n",
      "  3.3380e-01  4.4909e-01 -8.9773e-01  ...  -7.2307e-01 -1.9093e-01  2.3512e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.9967e+00  1.2341e+00 -1.6547e+00  ...   6.3107e-01 -1.3628e+00 -5.2214e-01\n",
      " -5.8069e-02 -6.2643e-01 -3.3153e-01  ...   1.3540e-01 -1.5861e-01 -9.4781e-01\n",
      "  1.0798e+00  3.3206e-01 -1.0704e+00  ...   1.4337e+00  4.8367e-01  1.0984e+00\n",
      "    ... \n",
      "\n",
      "( 0 ,97 ,.,.) = \n",
      "  1.2413e+00  7.6360e-01 -2.4186e-02  ...   3.1222e-01  1.5899e+00  8.5010e-01\n",
      " -1.2789e+00  1.0901e-01  1.9267e+00  ...   3.8675e-01  5.9015e-01 -3.5298e-01\n",
      " -2.1868e-01 -7.9679e-01 -1.4387e+00  ...   3.4984e-01  1.5147e-01  2.5522e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -9.9729e-01 -1.3551e-01 -8.1645e-01  ...  -1.7470e-01  1.5250e+00  6.8394e-01\n",
      "  1.2919e+00  7.0740e-01 -1.1859e+00  ...  -8.8213e-01  1.2926e+00  1.2864e+00\n",
      " -2.8957e+00 -9.9791e-01 -1.2249e+00  ...  -4.5172e-02 -3.5082e-01  4.7443e-01\n",
      "\n",
      "( 0 ,98 ,.,.) = \n",
      " -2.1923e-01 -1.4210e-01  9.8723e-01  ...  -7.7857e-01  3.6915e-01  1.6854e+00\n",
      " -2.6890e+00 -8.4222e-01 -2.4169e+00  ...  -6.4470e-01  1.8135e+00  3.9370e-01\n",
      " -1.2458e-01  4.4930e-01 -1.4060e+00  ...  -9.6944e-01  1.0649e+00 -3.1240e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.1353e-01 -1.1164e+00 -2.2220e+00  ...   1.2413e+00 -3.6280e-02  1.7045e-01\n",
      "  6.5892e-01 -5.8552e-01  6.6604e-01  ...   7.7857e-01  5.5363e-01 -3.0393e-01\n",
      " -8.1555e-01 -8.4591e-02  6.5139e-01  ...  -9.6862e-01 -1.4305e+00  2.5733e-01\n",
      "\n",
      "( 0 ,99 ,.,.) = \n",
      " -7.5458e-01 -1.3470e+00 -2.4654e-01  ...  -1.9762e+00  1.8050e-01 -3.5528e-01\n",
      " -1.8715e-01  2.0413e-02 -4.3549e-01  ...   1.9500e-04  1.0497e+00  2.9969e-01\n",
      " -9.8853e-01 -4.9455e-01 -7.0683e-01  ...  -2.3690e-01  2.9809e-01 -1.8820e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.7869e-01  1.1736e+00 -1.4112e+00  ...   6.2757e-02 -9.7885e-01 -5.0334e-01\n",
      " -1.4692e+00 -7.9091e-01 -8.5788e-01  ...  -1.9497e-02  3.1405e-01  1.4774e-01\n",
      " -3.2593e-01  1.6112e+00 -4.0802e-01  ...  -3.5359e-02  8.3227e-01 -2.7214e-01\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      " -6.9035e-01  7.3701e-01  9.3096e-01  ...  -1.7621e+00  5.9670e-01  7.7440e-01\n",
      " -1.2888e+00  1.4195e+00  4.0803e-01  ...  -4.0879e-01  1.0223e-01 -1.9629e+00\n",
      " -9.9521e-01 -7.7120e-01 -8.3290e-01  ...   3.6630e-01  8.0151e-01 -2.7440e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.9125e-01  1.4390e+00 -3.5202e-01  ...  -7.1636e-01  6.8502e-01 -1.0064e+00\n",
      " -3.0087e-01 -1.9851e-02  1.1861e+00  ...   1.6224e+00 -2.6013e-01  3.7684e-01\n",
      " -9.2657e-01 -8.7090e-01 -1.3014e+00  ...   2.6826e-01 -4.5086e-01  1.2138e+00\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -6.5970e-01  2.5875e-01  8.5331e-01  ...   1.6277e+00  1.1184e+00 -8.4600e-01\n",
      " -4.9581e-01  1.7176e+00 -8.0372e-01  ...   3.6767e-01  2.6736e-01  5.2547e-01\n",
      " -1.6849e+00 -4.1678e-01  2.7975e-02  ...  -6.2905e-01 -1.6932e+00  2.6980e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.1807e+00 -2.7939e-01 -9.0956e-01  ...   2.7769e-02 -1.4021e+00  1.2791e+00\n",
      " -3.3858e-01  1.8130e+00 -2.6864e+00  ...  -2.0488e-01  1.8539e-02 -3.2127e-01\n",
      " -1.9104e+00 -5.9289e-01 -7.8025e-01  ...  -4.1284e-01 -2.2488e-01  2.0817e+00\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  1.2871e+00  6.1398e-01  4.3183e-01  ...  -2.5380e+00 -1.9246e+00  2.1830e-01\n",
      "  2.4946e+00  1.3795e-01 -2.1986e+00  ...   1.6467e+00  8.6251e-01  6.4652e-01\n",
      "  3.8367e-01  3.2370e+00  1.5045e+00  ...  -9.0550e-01 -1.5024e+00  5.9849e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  4.9898e-01  1.5729e+00  1.8790e+00  ...   4.4247e-01 -7.5996e-01  2.6213e-01\n",
      "  8.5441e-01  6.6468e-01 -1.0556e+00  ...  -9.8543e-01 -2.7974e-02 -9.8573e-01\n",
      "  3.7677e-01 -3.1351e-02 -9.8768e-01  ...  -9.8241e-01 -6.6434e-01  2.5011e-01\n",
      "    ... \n",
      "\n",
      "( 1 ,97 ,.,.) = \n",
      " -2.0938e-02  1.3975e+00  1.1516e+00  ...   1.4930e+00 -1.6691e+00 -1.5852e+00\n",
      " -1.9874e+00 -7.7178e-01  1.0957e+00  ...   1.0459e+00 -7.7020e-01 -4.7425e-01\n",
      " -1.5133e-01  6.6135e-01 -2.4754e-01  ...   5.6765e-01  8.8784e-01 -2.8277e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -5.2307e-01  1.1805e-01 -5.3159e-01  ...  -9.2540e-01  1.8967e-01  1.5614e+00\n",
      " -2.3753e+00  8.3012e-01 -2.1368e+00  ...  -1.5765e+00  1.0439e+00 -1.7046e+00\n",
      " -1.0725e+00 -3.4043e-01  1.1431e+00  ...  -4.5296e-01  1.7502e-01 -3.8034e-01\n",
      "\n",
      "( 1 ,98 ,.,.) = \n",
      "  1.7648e+00  1.1225e+00  1.1786e+00  ...   4.4652e-01 -1.0687e+00 -1.2539e+00\n",
      " -1.9226e+00  1.4905e+00  1.2120e+00  ...   1.9282e+00  2.4489e+00 -2.0100e-01\n",
      " -1.4999e+00 -1.2332e-01 -8.3455e-01  ...  -2.6598e-01  2.1405e+00 -1.0391e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4304e-01  6.6635e-01 -1.1601e+00  ...   7.8620e-01  7.5557e-01  1.0639e+00\n",
      " -2.7072e-01 -3.1770e-01 -1.3118e+00  ...   4.3490e-01  1.5405e+00 -5.6055e-01\n",
      "  1.4114e+00  1.4054e-01  1.2307e+00  ...   2.4828e-01 -8.8674e-01 -1.3047e+00\n",
      "\n",
      "( 1 ,99 ,.,.) = \n",
      "  8.5711e-01 -4.8638e-01 -2.0231e+00  ...   5.3786e-01  1.0749e+00  1.9900e-01\n",
      " -9.8553e-01  2.8444e-01 -2.1009e-01  ...  -1.3444e-01  3.9274e-01 -1.3826e+00\n",
      " -1.9395e-01 -1.2695e+00 -3.0005e+00  ...   1.1643e+00  1.9494e+00 -1.7103e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.3294e-01  1.1391e+00  7.5371e-01  ...   4.4524e-02 -4.8362e-01 -5.4520e-01\n",
      "  3.7537e-01 -6.2497e-01  4.2314e-02  ...  -7.5356e-01  4.4181e-01 -1.1922e+00\n",
      " -1.2999e-01 -1.5506e-01 -6.8741e-01  ...  -1.0758e+00  1.6687e+00 -1.3305e+00\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -2.6244e-01 -4.9255e-01  4.3866e-01  ...   2.3526e-01 -6.4034e-01  5.9027e-01\n",
      "  4.6861e-02  8.3631e-01  5.4940e-01  ...   9.2449e-01 -1.3602e+00  1.0497e+00\n",
      " -1.7387e-01  7.2435e-01 -1.3510e+00  ...   1.7699e+00  2.4630e+00 -1.1744e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.4227e+00 -4.2941e-01 -3.3667e-01  ...   1.1997e+00 -1.5613e+00 -1.3438e+00\n",
      "  2.9928e-01 -8.7092e-02  5.4466e-02  ...   7.1973e-01  4.9173e-01 -4.7880e-02\n",
      " -1.9224e-01 -2.3757e-01 -9.8321e-01  ...  -1.0118e+00 -8.0033e-01 -1.3078e+00\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      " -1.1585e+00  1.0613e+00 -1.1391e+00  ...  -4.0622e-01  8.7177e-01 -1.0971e+00\n",
      "  8.4499e-01 -2.2407e+00  5.0418e-01  ...   5.2068e-01 -2.9885e-01 -8.0323e-02\n",
      "  2.3265e-02 -5.0611e-01 -3.1199e-01  ...   1.5761e-01 -2.1480e-03 -6.4503e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  4.3414e-01 -8.8364e-01  6.5740e-01  ...   2.3126e-01 -2.4589e-02 -1.3110e-01\n",
      " -5.6904e-01  6.1144e-01 -1.7220e+00  ...   3.8001e-02 -1.0566e+00  3.1466e-01\n",
      " -1.6871e+00 -2.2923e+00 -3.0763e-01  ...   1.7174e+00  9.8218e-02 -3.8549e-01\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      " -6.5200e-01  1.6662e-01 -5.5775e-02  ...  -1.8356e-01  1.0760e-01 -1.2188e+00\n",
      "  1.2112e+00 -9.8749e-01  1.1675e+00  ...  -5.1975e-01  8.4421e-01  1.2934e+00\n",
      " -9.0511e-01  9.3893e-01  1.4991e+00  ...   5.3644e-01 -4.8503e-01 -1.5608e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.2841e-01 -3.7593e-01 -2.6444e+00  ...   5.6564e-02 -2.1487e+00 -7.5129e-01\n",
      "  2.2952e-01  1.0381e+00 -4.1126e-01  ...  -1.1139e+00  1.6408e+00 -1.7227e-02\n",
      "  2.2527e+00  6.3894e-01  1.1854e+00  ...  -1.5687e+00  6.6520e-02  2.2035e-01\n",
      "    ... \n",
      "\n",
      "( 2 ,97 ,.,.) = \n",
      " -5.1140e-01  9.4081e-01 -1.6577e+00  ...   8.9929e-01  9.5935e-01  9.1006e-02\n",
      " -2.2969e+00  8.9184e-01 -1.0181e-02  ...  -2.9937e-01  6.1856e-01  3.2935e-01\n",
      " -4.4870e-01  1.0163e+00  1.7610e-01  ...   1.5338e+00 -1.7022e+00 -7.3673e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.0411e+00  7.0770e-01  4.2846e-01  ...  -3.5008e-01 -8.7879e-01 -4.9401e-01\n",
      " -9.8360e-01  1.6467e+00 -2.1148e+00  ...   4.7507e-01  6.3035e-01 -5.3707e-02\n",
      "  2.1450e+00 -9.4571e-03  7.9578e-01  ...  -5.0632e-01  1.8718e+00 -2.1699e+00\n",
      "\n",
      "( 2 ,98 ,.,.) = \n",
      " -2.5808e-01 -4.5471e-01  2.3527e-01  ...  -6.1026e-01  4.7526e-01  8.8979e-01\n",
      "  1.2356e-01 -2.8662e-01  1.7265e-01  ...  -9.8826e-01 -8.4763e-01 -2.9579e-01\n",
      "  1.1350e+00  1.7776e+00  7.1634e-02  ...  -3.3835e-01 -2.4268e+00  3.1157e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.5451e-01 -1.1518e+00 -4.3767e-01  ...  -5.8796e-02  1.4325e+00 -4.7594e-02\n",
      " -5.3433e-01  7.7927e-01  9.7848e-01  ...   1.0502e-01  3.5304e-01 -1.9936e-01\n",
      "  6.6678e-01  8.5937e-02 -1.0929e+00  ...  -8.1904e-01 -6.7228e-01  1.3654e+00\n",
      "\n",
      "( 2 ,99 ,.,.) = \n",
      "  7.3435e-02 -1.5556e+00 -3.8038e-01  ...  -7.7918e-01  4.5057e-01  4.0203e-01\n",
      " -1.3747e+00 -1.4125e+00 -1.6121e+00  ...   1.8994e-01 -9.0946e-01  6.7092e-01\n",
      " -5.7615e-01  1.5143e-01 -1.1358e+00  ...  -6.3385e-01 -6.8455e-01 -7.7330e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.2730e-01  1.1625e+00  7.0924e-01  ...  -3.7037e-01  2.9200e-01 -1.0864e+00\n",
      " -1.5804e+00 -1.6778e+00  1.8572e+00  ...  -3.0165e-01 -9.4138e-01  2.1588e+00\n",
      "  1.7390e-01 -1.9294e-01 -9.4573e-02  ...   3.7620e-01 -1.8779e-01 -3.1431e-01\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(17 , 0 ,.,.) = \n",
      " -3.0591e+00 -5.9580e-01 -9.4879e-02  ...   4.8138e-01 -1.3432e+00 -2.9275e-01\n",
      " -6.5973e-02  4.5887e-01  8.7570e-01  ...   3.1912e-04  5.0465e-01 -1.8683e-01\n",
      " -8.1167e-01 -8.2239e-01 -1.4606e+00  ...  -2.6964e-03 -1.5591e+00  1.5981e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.9305e-01 -1.4325e+00  1.8341e-01  ...   1.9996e-02 -2.4936e-01 -6.0710e-02\n",
      "  1.8226e-01  1.4947e-01  5.8361e-01  ...   1.0101e+00 -1.1593e+00 -7.3453e-01\n",
      "  1.0099e+00 -4.0327e-01 -4.8330e-01  ...  -1.2478e-01 -1.7862e-01  6.0156e-01\n",
      "\n",
      "(17 , 1 ,.,.) = \n",
      "  1.2043e+00 -7.3935e-01 -7.2174e-01  ...  -5.2137e-01 -5.3705e-01  1.2717e-01\n",
      " -1.3133e+00  6.8825e-01 -1.0658e+00  ...  -1.0305e+00 -6.6038e-02 -5.4797e-01\n",
      "  3.1233e-01  1.3825e+00  3.1208e-01  ...  -1.3124e+00  2.5366e+00  4.8440e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.2939e-01 -4.2707e-01  3.7757e-01  ...  -2.2074e-01  6.4208e-02  1.6695e+00\n",
      "  6.8347e-01 -8.1269e-01  2.1663e+00  ...  -6.2070e-01 -2.1457e-02 -3.0995e-04\n",
      " -1.1862e+00  1.5884e+00 -1.0964e-01  ...  -1.2466e-01  4.7636e-01  6.5161e-01\n",
      "\n",
      "(17 , 2 ,.,.) = \n",
      " -2.3923e-01 -1.7802e-01  8.1612e-01  ...  -9.7637e-02  1.1136e+00 -7.9065e-02\n",
      "  3.9315e-01 -7.1293e-01 -4.8173e-01  ...  -8.2286e-02 -7.6705e-02  2.7601e-01\n",
      "  1.3298e+00 -6.9267e-01 -2.0405e-01  ...   1.1372e+00  1.4782e+00 -5.0794e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.1078e-01  4.2276e-01 -1.9227e+00  ...   6.3822e-02 -8.8737e-01 -5.6858e-01\n",
      " -3.8652e-01  8.5296e-01  7.5539e-01  ...   1.0449e-01  8.7767e-01 -1.5033e-01\n",
      " -1.5252e+00 -6.1987e-01 -5.2465e-01  ...   1.9674e-01 -1.0074e+00  5.3485e-01\n",
      "    ... \n",
      "\n",
      "(17 ,97 ,.,.) = \n",
      "  2.5054e+00  8.2223e-01 -2.9215e-01  ...   9.4871e-01  3.5188e-01  1.0237e+00\n",
      "  1.5623e-01  4.1811e-01  1.0387e+00  ...   1.3690e+00  1.3796e+00  4.0189e-01\n",
      "  1.2373e+00  5.2823e-01  1.0515e+00  ...  -2.7774e-01 -1.8209e+00 -8.9488e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.2857e+00 -1.2827e+00  7.3621e-01  ...  -2.9877e-01  3.6224e-01  1.2157e+00\n",
      " -2.7011e+00 -1.0363e+00  1.5798e+00  ...   1.2450e-01 -2.6984e+00 -1.0965e+00\n",
      "  4.5388e-01 -1.4401e-01  2.3736e+00  ...  -7.9481e-01  4.2754e-01 -1.1589e+00\n",
      "\n",
      "(17 ,98 ,.,.) = \n",
      " -8.1883e-01 -3.2326e-02 -1.4909e-01  ...   1.5108e+00 -1.0818e+00 -6.1383e-01\n",
      " -1.2100e+00 -8.7680e-01  2.3753e+00  ...   8.1320e-03 -3.6774e-01 -4.2194e-01\n",
      "  2.4911e+00  1.3983e+00  4.7210e-01  ...  -2.3292e-01  1.8219e-01  1.2310e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.4651e+00 -5.2257e-01  1.8564e+00  ...  -8.3789e-02  1.7714e+00 -1.4019e+00\n",
      "  2.4671e+00  2.4925e-01 -1.2524e+00  ...   5.6848e-01  9.0974e-01 -1.1596e+00\n",
      "  6.5299e-01  2.3844e+00 -2.6253e-01  ...  -4.0100e-01 -2.6228e+00  6.9347e-01\n",
      "\n",
      "(17 ,99 ,.,.) = \n",
      "  1.1133e-01 -9.9187e-02  4.7666e-01  ...  -5.4167e-01 -2.8716e-01 -1.3025e+00\n",
      " -6.7850e-02 -1.0457e+00 -3.7242e-01  ...  -9.7702e-01 -2.5989e-01 -1.7262e+00\n",
      " -1.8687e+00 -8.7709e-01 -8.9065e-01  ...  -1.9554e+00 -6.8573e-01 -5.2062e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  5.4328e-01  1.7468e+00 -7.3754e-01  ...   9.0078e-01  3.2416e-01 -1.4985e+00\n",
      "  1.0633e+00 -3.5023e-01  4.2123e-01  ...   9.7596e-01 -1.2106e-02 -2.0922e+00\n",
      "  1.6913e-01 -8.5109e-01  1.9996e+00  ...  -9.9539e-01  3.0453e-01  1.4663e+00\n",
      "      ⋮  \n",
      "\n",
      "(18 , 0 ,.,.) = \n",
      "  1.6872e+00 -1.0810e+00 -2.6764e-02  ...  -2.9581e-01  1.4453e-01  2.1753e-01\n",
      " -6.9063e-01  1.5416e+00 -4.6271e-01  ...   3.1941e-01 -7.2426e-01 -1.1260e+00\n",
      "  1.3576e+00 -2.3887e-02  8.5382e-02  ...  -1.2746e+00  1.3854e+00 -4.6675e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.7998e+00  9.9023e-01 -2.2569e-01  ...   1.4347e+00 -1.3631e+00  7.5795e-01\n",
      " -2.0456e+00 -2.1705e-02  6.1307e-01  ...   3.1614e-01  3.9040e-01  8.5684e-01\n",
      " -1.4302e+00  7.4874e-01  7.1746e-01  ...  -1.3708e+00 -6.1979e-01  8.6458e-01\n",
      "\n",
      "(18 , 1 ,.,.) = \n",
      " -3.8602e-01 -3.0386e-01 -7.9706e-01  ...   4.1891e-01 -1.4294e-01  5.4756e-01\n",
      "  1.5568e-01 -4.7009e-01 -9.4319e-01  ...  -6.8251e-02  7.6470e-01 -5.1102e-01\n",
      "  3.8288e-01 -1.7556e-01  5.5652e-01  ...   2.1859e+00  9.1470e-01  1.2173e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.7208e-01 -7.5288e-01 -3.4726e-01  ...   4.9795e-01  5.3891e-01  1.6354e+00\n",
      "  2.0096e-01  3.5950e-01 -5.2378e-01  ...   1.1098e+00  1.2537e+00 -2.7175e-03\n",
      " -9.8444e-01 -1.6701e-01 -1.5514e-01  ...   9.8967e-01  7.8331e-01 -2.5163e-01\n",
      "\n",
      "(18 , 2 ,.,.) = \n",
      " -3.3260e-02  3.8571e-01 -1.9912e+00  ...   1.2080e-01 -1.8967e-01  3.6847e-01\n",
      " -3.4610e-02  1.1722e+00  3.4289e-01  ...  -1.4023e+00  7.7901e-01 -1.1588e+00\n",
      "  8.5089e-02  1.6457e+00 -2.3397e-01  ...   7.9676e-02 -5.0320e-01 -1.8916e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  4.1866e-01 -4.0559e-01 -1.2703e+00  ...   6.1403e-01 -6.0837e-01  1.1237e-01\n",
      "  9.9368e-01 -1.3845e-02 -2.8955e-01  ...  -5.7669e-01  1.3668e+00  3.4401e+00\n",
      "  3.6415e-01  3.3067e+00 -2.5004e-01  ...  -5.6122e-01 -5.1226e-01 -1.2056e+00\n",
      "    ... \n",
      "\n",
      "(18 ,97 ,.,.) = \n",
      "  7.2158e-02  3.4918e-01  7.7281e-01  ...  -1.3756e+00  5.2597e-01 -2.6680e-01\n",
      " -4.3327e-01  1.5897e-01 -6.0426e-01  ...  -9.4673e-01  6.6511e-01 -9.0039e-01\n",
      "  5.0309e-01 -1.0682e+00  1.1270e+00  ...  -1.0183e+00  7.2366e-01 -7.1031e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -5.9952e-01 -8.5136e-01  7.2659e-01  ...  -8.7957e-01 -1.2878e+00 -4.5501e-01\n",
      "  1.4040e+00 -7.6763e-01  1.5036e+00  ...   9.5614e-01 -5.4417e-01 -1.3177e+00\n",
      "  1.8959e-02 -3.8126e-01  9.4402e-01  ...   3.4088e-01  4.2664e-01  4.8224e-01\n",
      "\n",
      "(18 ,98 ,.,.) = \n",
      " -5.1428e-01 -7.7909e-03  7.6241e-01  ...   1.4037e+00 -1.7185e-01 -6.4766e-01\n",
      " -2.9939e-01 -5.0845e-01  1.7771e-01  ...   1.8470e+00 -1.8745e-01 -6.1687e-01\n",
      "  1.0431e-01  1.1352e+00  1.3650e+00  ...  -1.4428e-01 -5.0480e-01 -4.3100e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.9174e+00 -2.0518e-01  2.1393e+00  ...  -2.0021e+00 -4.1970e-01  3.3666e-01\n",
      " -2.1467e+00  3.6694e-01 -1.3845e+00  ...   4.8618e-01 -5.3042e-01  2.2388e-01\n",
      "  9.1984e-01  1.2872e+00  1.5738e+00  ...  -3.3526e-01 -1.7182e-01  1.5778e+00\n",
      "\n",
      "(18 ,99 ,.,.) = \n",
      " -1.8638e+00  1.9105e-01  7.0515e-01  ...  -1.7019e-01 -1.1689e+00 -1.5041e+00\n",
      " -3.1600e-01 -2.1166e+00  6.1946e-01  ...  -1.6763e+00 -1.0014e+00 -2.5074e-01\n",
      " -7.3476e-01 -1.8754e+00 -1.0400e+00  ...   3.2697e-01 -1.2966e+00 -5.7678e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.2703e+00  7.8519e-02 -1.0595e+00  ...  -9.9565e-01  1.2518e-01 -7.5393e-01\n",
      "  1.7036e+00 -4.5341e-01 -2.5164e-01  ...   1.2876e+00 -1.2502e+00 -4.9303e-01\n",
      " -5.0049e-02  7.7823e-01 -3.5950e-01  ...  -2.4293e-01  4.9059e-02  1.0993e+00\n",
      "      ⋮  \n",
      "\n",
      "(19 , 0 ,.,.) = \n",
      " -2.7201e-01 -1.9641e-01  8.6749e-01  ...  -1.2324e+00  2.7958e-01  1.2843e+00\n",
      " -1.8856e+00  1.8165e+00  5.5935e-01  ...  -8.8295e-01  7.6849e-01  4.4915e-01\n",
      " -9.2129e-01  1.7214e-01 -2.0838e-01  ...   3.7657e-01  9.8395e-01  6.0684e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.4409e-01 -4.7108e-01  1.3130e-01  ...   4.7200e-01 -1.5098e+00 -1.2001e+00\n",
      "  9.4498e-01 -1.2337e+00  2.9363e-01  ...   4.6915e-01 -6.3826e-01 -6.0765e-01\n",
      " -2.2782e-01 -5.5878e-01  1.2680e-01  ...   1.9838e-01 -8.7920e-01 -1.4641e+00\n",
      "\n",
      "(19 , 1 ,.,.) = \n",
      "  4.0051e-01  8.0899e-02  1.9326e+00  ...   4.8055e-01 -4.0895e-01  1.1624e+00\n",
      " -7.6212e-02  4.1184e-01 -4.4697e-01  ...   6.6266e-01  4.8927e-01  9.5301e-01\n",
      "  1.0655e-01 -3.5064e-01 -1.5373e-01  ...   8.5637e-01 -7.3965e-01  1.5941e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -6.3494e-01  2.1747e-01  1.0345e-01  ...   3.6268e-02  6.1720e-01  4.0561e-01\n",
      " -1.0795e-01 -7.2166e-02  5.0766e-01  ...   2.8860e-01 -1.7569e-01 -7.6217e-01\n",
      "  6.5819e-01  5.7705e-01  5.6734e-01  ...  -7.9417e-01 -1.6146e+00  4.8598e-01\n",
      "\n",
      "(19 , 2 ,.,.) = \n",
      " -8.9957e-01  6.0304e-01  1.6334e+00  ...  -4.5841e-01  1.1975e-01  2.3609e-01\n",
      " -5.5462e-01 -1.9669e+00 -9.6355e-01  ...  -4.4666e-01  5.4678e-02 -1.7872e+00\n",
      " -6.6130e-02  1.2139e+00 -2.8236e-01  ...  -1.0982e+00  4.0217e-01 -2.7194e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  3.0226e-02 -1.8330e+00  2.1988e+00  ...   1.0047e+00 -1.1673e-01  4.6981e-01\n",
      "  1.2270e+00  1.9268e-01  2.8980e-01  ...  -5.8955e-01  8.7072e-01  1.2365e-01\n",
      " -1.3091e+00 -7.0534e-01 -4.8006e-01  ...  -9.8436e-03  4.8378e-02 -3.6154e-01\n",
      "    ... \n",
      "\n",
      "(19 ,97 ,.,.) = \n",
      "  4.1660e-02  4.9732e-01  5.9951e-01  ...  -2.5269e-01  4.9669e-01  1.9041e+00\n",
      "  1.9510e+00  6.9602e-01  3.2632e-01  ...  -6.2905e-01 -6.9462e-01 -1.7812e+00\n",
      "  4.8759e-01 -1.0912e+00 -5.9177e-01  ...   1.0989e+00 -2.5189e-01  1.0304e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.1796e-02 -1.8118e+00  2.2497e-01  ...  -2.0497e+00 -9.3694e-03  5.1330e-01\n",
      "  8.3432e-01 -5.2285e-01 -1.1619e-01  ...   2.6789e-01 -9.9363e-02  2.2064e-01\n",
      " -4.1944e-02  4.5075e-01 -2.8766e+00  ...  -6.5337e-01 -1.9384e-01  1.5913e+00\n",
      "\n",
      "(19 ,98 ,.,.) = \n",
      "  1.2261e+00 -5.4812e-01 -9.9153e-01  ...  -1.2833e+00  1.0074e+00 -1.4166e+00\n",
      " -1.4983e-01  8.1176e-01 -1.5212e-01  ...  -4.8487e-01 -7.1030e-01  8.7840e-01\n",
      " -7.7238e-01  8.5670e-01 -1.4929e+00  ...   8.5240e-01 -1.0714e+00  4.9746e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.4797e-01 -1.0672e+00  7.2309e-02  ...  -8.0890e-01 -5.4858e-01 -1.6606e+00\n",
      "  7.8567e-02 -5.3930e-01 -7.2413e-01  ...   1.1249e+00  3.6467e-01 -1.2046e+00\n",
      " -1.0998e+00 -1.7908e+00  1.2355e+00  ...   1.2500e-02 -6.9121e-01 -3.1529e-01\n",
      "\n",
      "(19 ,99 ,.,.) = \n",
      "  8.2831e-01  1.2900e+00  1.3050e-01  ...   5.8371e-02 -3.0944e-01 -9.0783e-01\n",
      "  1.0929e+00 -2.5520e-02 -3.2109e-01  ...  -9.3435e-01  3.4310e-01  1.5784e+00\n",
      "  8.8242e-01 -8.8078e-01 -1.9118e+00  ...  -3.4473e-02 -6.5073e-01 -2.7047e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  3.8939e-01 -1.1628e+00 -1.2555e+00  ...   1.0495e+00  1.0782e+00 -2.1699e+00\n",
      "  2.7868e+00  2.9058e-01  6.6309e-01  ...  -4.5591e-02 -3.5357e-01 -4.9172e-01\n",
      "  1.0315e+00 -9.5352e-01 -1.9531e-01  ...   6.0136e-01  4.5639e-01 -2.5870e-01\n",
      "[torch.FloatTensor of size 20x100x35x45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "m = nn.BatchNorm2d(100, affine = False)\n",
    "input = Variable(torch.randn(20, 100, 35, 45))\n",
    "output = m(input) \n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 10])\n",
      "torch.Size([6, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "#RNN网络，input的维度为5，隐层维度为10，网络层数为2\n",
    "rnn = nn.RNN(5, 10, 2)\n",
    "input = Variable(torch.randn(6, 3, 5))\n",
    "#h0为输入序列，长为2，batch为3，特征是20\n",
    "# h0 = Variable(torch.randn(2, 3, 20))\n",
    "output, hn = rnn(input)\n",
    "print(hn.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "-0.2311  0.2125\n",
      "-0.5239 -0.3120\n",
      " 0.4855 -0.4640\n",
      " 0.1824 -0.1616\n",
      "[torch.FloatTensor of size 4x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "line = nn.Linear(2,4) #输入2维，输出4维\n",
    "x = Variable(torch.randn(5, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-81eae90dbcfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "lstm = nn.LSTM(10, 20, 2)\n",
    "input = Variable(torch.randn(5, 3, 10))\n",
    "h0 = Variable(torch.randn(2, 3, 20))\n",
    "c0 = Variable(torch.randn(2, 3, 20))\n",
    "output, hn = lstm(input, (h0, c0))\n",
    "print(output.size())\n",
    "print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b3a1856dd612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(10, 20, 2)\n",
    "input = Variable(torch.randn(5, 3, 10))\n",
    "h0 = Variable(torch.randn(2, 3, 20))\n",
    "c0 = Variable(torch.randn(2, 3, 20))\n",
    "output, hn = lstm(input, (h0, c0))\n",
    "print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Dropout2d(p = 0.2)\n",
    "input = Variable(torch.randn(20, 16, 32, 32))\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "[torch.FloatTensor of size 1x26]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "#pytorch实现最简单RNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    #input_size：char_vacab_size=26,最长词汇长度\n",
    "    #;hidden_size隐层神经元数，随意定；output_size为要分成的类\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size+hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "    \n",
    "n_hidden = 128\n",
    "target_size = 10\n",
    "rnn = RNN(26, n_hidden, target_size)\n",
    "hidden = rnn.initHidden()\n",
    "#batch = 1\n",
    "input = Variable(torch.zeros((1, 26)))\n",
    "print(input)\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "#output:[batch, output_size]; hidden[batch, hidden_size]\n",
    "print(output.data.size(), next_hidden.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 10])\n",
      "torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "#人工输入：RNN[input_dim, hidden_dim, num_layers];\n",
    "#人工输入：X(input)[seq, batch, input_dim]\n",
    "#人工输入：h0[num_layers, batch, hidden_dim]\n",
    "#自动输出：output_size[seq, batch, hidden_dim]\n",
    "#自动输出：hn[num_layers, batch, hidden_dim]\n",
    "rnn = nn.RNN(10, 10, 1)\n",
    "\n",
    "inputR = Variable(torch.randn(2, 1, 10))\n",
    "\n",
    "h0 = Variable(torch.randn(1, 1, 10))\n",
    "\n",
    "output, hn = rnn(inputR, h0)\n",
    "print(output.size())\n",
    "print(hn.size())\n",
    "\n",
    "\n",
    "\n",
    "# lstm = nn.LSTM(10, 20, 2)\n",
    "# input = Variable(torch.randn(5, 3, 10))\n",
    "# h0 = Variable(torch.randn(2, 3, 20))\n",
    "# c0 = Variable(torch.randn(2, 3, 20))\n",
    "# output, hn = lstm(input, (h0, c0))\n",
    "# print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2972  1.0568  0.1863 -0.2593\n",
      "-0.5907  0.6893 -1.3976  0.3979\n",
      "-0.1459 -0.2090 -1.5423  0.1128\n",
      "-0.6888  0.4190 -1.7717  0.4798\n",
      "-0.0157  1.4514  0.0823 -0.0491\n",
      "[torch.FloatTensor of size 5x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "line = nn.Linear(2, 4)\n",
    "x = Variable(torch.randn(5, 2))\n",
    "print(line(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 100])\n",
      "torch.Size([2, 3, 100])\n"
     ]
    }
   ],
   "source": [
    "lstm_seq = nn.LSTM(50, 100, num_layers = 2)\n",
    "lstm_input = Variable(torch.randn(10, 3, 50))\n",
    "out, (h, c) = lstm_seq(lstm_input)\n",
    "print(out.size())\n",
    "print(h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "-0.8184  1.0675 -0.5023  0.4886 -0.8586\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n",
      "Variable containing:\n",
      "-1.6816  0.1445  0.9216  2.5445  0.3630\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pytorch_WordEmbedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "word2id = {'hello':0, 'world':1}\n",
    "embeds = nn.Embedding(2, 5)\n",
    "hello_index = torch.LongTensor([word2id['hello']])\n",
    "print(hello_index)\n",
    "hello_idx = Variable(hello_index)\n",
    "print(hello_index)\n",
    "hello_embed = embeds(hello_idx)\n",
    "print(hello_embed)\n",
    "world_embed = embeds(Variable(torch.LongTensor([word2id['world']])))\n",
    "print(world_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e61ea241a4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    396\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 398\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "out_size = nn.Linear(32, 1)\n",
    "print(out_size.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6047d1299c71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# shape (batch, time_step, input_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# rnn output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;31m# 这一步非常重要\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mh_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;31m# 重置隐藏层的状态, 切断和前一次迭代的链接\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-6047d1299c71>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, h_state)\u001b[0m\n\u001b[0;32m     26\u001b[0m          \u001b[1;31m# h_state (n_layers, batch, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m          \u001b[1;31m# r_out (batch, time_step, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mr_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 保存所有的预测值\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 计算每一步长的预测值\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mnum_directions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             hx = torch.autograd.Variable(input.data.new(self.num_layers *\n\u001b[0m\u001b[0;32m    176\u001b[0m                                                         \u001b[0mnum_directions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                                                         \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mdata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;31m# Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "TIME_STEP = 40 # rnn 时序步长数\n",
    "INPUT_SIZE = 1 # rnn 的输入维度\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "H_SIZE = 128 # of rnn 隐藏单元个数\n",
    "EPOCHS=480 # 总共训练次数\n",
    "h_state = None # 隐藏层状态\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "        input_size=INPUT_SIZE,\n",
    "        hidden_size=H_SIZE,\n",
    "        num_layers=1,\n",
    "        batch_first=True,\n",
    "        )\n",
    "        self.out = nn.Linear(H_SIZE, 1)\n",
    "    def forward(self, x, h_state):\n",
    "         # x (batch, time_step, input_size)\n",
    "         # h_state (n_layers, batch, hidden_size)\n",
    "         # r_out (batch, time_step, hidden_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        outs = [] # 保存所有的预测值\n",
    "        for time_step in range(r_out.size(1)): # 计算每一步长的预测值\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "         # 也可使用以下这样的返回值\n",
    "         # r_out = r_out.view(-1, 32)\n",
    "         # outs = self.out(r_out)\n",
    "         # return outs, h_state\n",
    "\n",
    "rnn = RNN()\n",
    "optimizer = torch.optim.Adam(rnn.parameters()) # Adam优化，几乎不用调参\n",
    "criterion = nn.MSELoss() # 因为最终的结果是一个数值，所以损失函数用均方误差\n",
    "\n",
    "rnn.train()\n",
    "plt.figure(2)\n",
    "for step in range(0,EPOCHS,2):\n",
    "    start, end = step * np.pi, (step+2)*np.pi # 一个时间周期\n",
    "    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32)\n",
    "    x_np = np.sin(steps)\n",
    "    y_np = np.cos(steps)\n",
    "    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis]) # shape (batch, time_step, input_size)\n",
    "    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])\n",
    "    prediction, h_state = rnn(x, h_state) # rnn output\n",
    "    # 这一步非常重要\n",
    "    h_state = h_state.data # 重置隐藏层的状态, 切断和前一次迭代的链接\n",
    "    loss = criterion(prediction, y)\n",
    "    # 这三行写在一起就可以\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (step)%20==0: #每训练20个批次可视化一下效果，并打印一下loss\n",
    "        print(\"EPOCHS: {},Loss:{:4f}\".format(step,loss))\n",
    "        plt.plot(steps, y_np.flatten(), 'r-')\n",
    "        plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(57, 18, 2)\n",
    "input = Variable(torch.randn(6, 1, 57))\n",
    "print(input.size(1))\n",
    "# h0 = Variable(torch.randn(2, 1, 18))\n",
    "# output, hn = rnn(input, h0)\n",
    "# print(input.size())\n",
    "# print(h0.size())\n",
    "\n",
    "# print(output.size())\n",
    "# print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_seq = nn.RNN(57, 32, 2)\n",
    "x = Variable(torch.randn(6, 1, 57))\n",
    "out,ht = rnn_seq(x, h_n)\n",
    "print(out.size())\n",
    "print(ht.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d0143486e4c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0minputA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# inputR = torch.cat((20, inputR))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(sequence, dim, out)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "rnn = nn.RNN(57, 128, 1)\n",
    "inputA = Variable(torch.zeros(1, 57))\n",
    "inputB = V\n",
    "# inputR = torch.cat((20, inputR))\n",
    "combined = torch.stack((inputA, inputA), 0)\n",
    "print(inputR.size())\n",
    "print(combined.size())\n",
    "# h0 =Variable(torch.zeros(1, 1, 128))\n",
    "# output, hn = rnn(inputR, h0)\n",
    "# print(inputR.size())\n",
    "# print(h0.size())\n",
    "# print(output.size())\n",
    "# print(hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "[torch.IntTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(1, 1)\n",
    "int_tensor = tensor.int()\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 18])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(57, 18)\n",
    "input = Variable(torch.randn(5, 1, 57))\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "----\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "----\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "----\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "----\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "----\n",
      "torch.Size([15, 1])\n",
      "torch.Size([15, 1])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Hyper-parameters 定义迭代次数， 学习率以及模型形状的超参数\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 6\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Toy dataset  1. 准备数据集\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "# Linear regression model  2. 定义网络结构 y=w*x+b 其中w的size [1,1], b的size[1,]\n",
    "model = nn.Linear(input_size, output_size)\n",
    "print(input_size)\n",
    "print(output_size)\n",
    "# Loss and optimizer 3.定义损失函数， 使用的是最小平方误差函数\n",
    "criterion = nn.MSELoss()\n",
    "# 4.定义迭代优化算法， 使用的是随机梯度下降算法\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "loss_dict = []\n",
    "# Train the model 5. 迭代训练\n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy arrays to torch tensors  5.1 准备tensor的训练数据和标签\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "    print(inputs.size())\n",
    "    print(targets.size())\n",
    "    print(\"----\")\n",
    "#     # Forward pass  5.2 前向传播计算网络结构的输出结果\n",
    "#     outputs = model(inputs)\n",
    "#     # 5.3 计算损失函数\n",
    "#     loss = criterion(outputs, targets)\n",
    "    \n",
    "#     # Backward and optimize 5.4 反向传播更新参数\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 17 \n",
      "    0     0     0     1     0\n",
      "[torch.FloatTensor of size 1x18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_num = 18\n",
    "batch_size = 1\n",
    "label = torch.LongTensor(batch_size, 1).random_()%class_num\n",
    "one_hot = torch.zeros(batch_size, class_num).scatter_(1, label, 1)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 18])\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.randn(7, 1, 18))\n",
    "b = torch.squeeze(a)\n",
    "print(b.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-0.3648  1.4396 -0.8218 -0.8106  1.4453 -0.1225 -0.5979  1.1894 -0.5866 -0.9484\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.4707  1.6356  0.1269 -0.3848  0.5783  1.4354  0.1051  0.9567 -1.1528 -0.0846\n",
      "\n",
      "Columns 20 to 29 \n",
      " 0.5259  1.5507  0.1056 -0.7784  0.0917  0.0938  1.7906 -0.0390  1.1176  1.9468\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.0496 -0.2872 -1.1698  0.3723 -0.7884  0.6187  0.1540 -1.4045 -0.3146 -0.4869\n",
      "\n",
      "Columns 40 to 49 \n",
      "-0.5533  0.5694 -0.2396 -0.0955  0.4740  0.6985 -0.2707 -0.0742  0.2723 -1.4426\n",
      "[torch.FloatTensor of size 1x50]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_to_idx = {'hello':0, 'world': 1}\n",
    "embeds = nn.Embedding(3, 50)\n",
    "hello_idx = torch.LongTensor([word_to_idx['hello']])\n",
    "hello_idx = Variable(hello_idx)\n",
    "hello_embed = embeds(hello_idx)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "#所有英文字母加上五个标点符号(包含一个空格)\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "# 将unicode转为ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "#build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "# read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "import os\n",
    "file_path = r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\Pytorch_名字分类\\data\\data\\names'\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for file in files:\n",
    "        category = file.split('/')[-1].split('.')[0]\n",
    "        all_categories.append(category)\n",
    "        lines = readLines(os.path.join(root, file))\n",
    "        category_lines[category] = lines\n",
    "n_categories = len(all_categories)\n",
    "print(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 1, 18])\n",
      "\n",
      "(0 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(1 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(2 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(3 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(4 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(5 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "(6 ,.,.) = \n",
      "   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "[torch.FloatTensor of size 7x1x18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "words = list(set(all_categories))\n",
    "word2ind = {word: i for i, word in enumerate(words)}\n",
    "\n",
    "# def Label_letterToTensor(letter):\n",
    "#     tensor = torch.zeros(1, n_letters)\n",
    "#     tensor[0][letterToIndex(letter)] = 1\n",
    "#     return tensor\n",
    "words = list(set(all_categories))\n",
    "word2ind = {word: i for i, word in enumerate(words)}\n",
    "def Label_lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_categories)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][word2ind['Chinese']] = 1\n",
    "    tensor = Variable(tensor)\n",
    "    return tensor\n",
    "\n",
    "print(Label_lineToTensor('Chinese').size())\n",
    "aa = Label_lineToTensor('Chinese').data\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PackedSequence' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9f287d928911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0munpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PackedSequence' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "#pytorch 文字长度pad\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import utils as nn_utils\n",
    "\n",
    "batch_size = 2\n",
    "max_length = 3\n",
    "hidden_size = 2\n",
    "n_layers = 1\n",
    "\n",
    "tensor_in = torch.FloatTensor([[1, 2, 3], [1, 0, 0]]).resize_(2, 3, 1)\n",
    "tensor_in = Variable(tensor_in)\n",
    "seq_lengths = [3, 1]\n",
    "#pack it\n",
    "pack = nn_utils.rnn.pack_padded_sequence(tensor_in, seq_lengths, batch_first = True)\n",
    "\n",
    "rnn = nn.RNN(1, hidden_size, n_layers, batch_first = True)\n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "\n",
    "out, _ = rnn(pack, h0)\n",
    "print(out.size())\n",
    "unpacked = nn_utils.rnn.pad_packed_sequence(out)\n",
    "\n",
    "print(\"111\", unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcsedf hioijllkm dadfsfadfs oipy hjyj\n",
      "-----\n",
      "[1 0]\n",
      "  hjyj oipy hioijllkm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def shuffle(text):\n",
    "    text = np.random.permutation(text.strip().split())\n",
    "    return ' '.join(text)\n",
    "\n",
    "def dropout(text, p=0.5):\n",
    "    # random delete some text\n",
    "    text = text.strip().split()\n",
    "    len_ = len(text)\n",
    "    indexs = np.random.choice(len_, int(len_ * p))\n",
    "    print(indexs)\n",
    "    for i in indexs:\n",
    "        text[i] = ''\n",
    "    return ' '.join(text)\n",
    "text = 'abcsedf dadfsfadfs hjyj oipy hioijllkm'\n",
    "print(shuffle(text))\n",
    "print(\"-----\")\n",
    "print(dropout(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_a', '1_b', '1_c']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test1_pd = pd.DataFrame({})\n",
    "test2_pd = pd.DataFrame({'a_columns':[], 'b_columns':[]})\n",
    "dict_name = {'test1_pd':['1_a', '1_b', '1_c']}\n",
    "print(dict_name['test1_pd'])\n",
    "# mapping_pd = pd.read_excel(r'C:\\Users\\lenovo\\Desktop\\Josie\\工作\\V2.0\\测试表.xlsx')\n",
    "# for index, i in enumerate(mapping_pd['dataframe_name']):\n",
    "#     trans = str(dict_name.keys())\n",
    "#     print(trans)\n",
    "#     if trans == i:\n",
    "#         print(trans, index)\n",
    "#     if dict_name.keys() == i:\n",
    "#         print('1')\n",
    "# print(mapping_pd.iat['test2_pd',1])\n",
    "# if test1_pd.columns.empty:\n",
    "#     #需要根据mapping表进行列名填充\n",
    "#     for index, i in enumerate(mapping_pd): \n",
    "#         print(mapping_pd[str(test1_pd)][1])\n",
    "#     test1_pd = pd.DataFrame(columns=['big', 'small'])\n",
    "# print(test1_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test1_pd = pd.DataFrame({})\n",
    "test2_pd = pd.DataFrame({'a_columns':[], 'b_columns':[]})\n",
    "dict_name = {'test1_pd':['1_a', '1_b', '1_c']}\n",
    "print(test1_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [1_a, 1_b, 1_c]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "columns = ['1_a', '1_b', '1_c']\n",
    "if test1_pd.columns.empty:\n",
    "    test1_pd = pd.DataFrame(columns=dict_name['test1_pd'])\n",
    "print(test1_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "'\n",
      "1\n",
      "_\n",
      "a\n",
      "'\n",
      ",\n",
      " \n",
      "'\n",
      "1\n",
      "_\n",
      "b\n",
      "'\n",
      ",\n",
      " \n",
      "'\n",
      "1\n",
      "_\n",
      "c\n",
      "'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "columns = str(['1_a', '1_b', '1_c'])\n",
    "for i in columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'中国': '1', '日本': '3', '美国': '2'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Indata=pd.DataFrame([['中国','1'],['日本','3'],['美国','2']],columns=['name','value'])\n",
    "dict_test = {}\n",
    "for index, content in Indata.iterrows():\n",
    "    dict_test[content[0]] = content[1]\n",
    "print(dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3],\n",
      "        [6],\n",
      "        [8],\n",
      "        [2]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class_num = 10\n",
    "batch_size = 4\n",
    "label = torch.LongTensor(batch_size, 1).random_()%class_num\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([tensor([], dtype=torch.int64), tensor([8031151179464336743]), tensor([0, 0]), tensor([  25896174598750208, 3834877979102766643, 7234300764517119280]), tensor([3546976558754378594, 3906648583439475761, 7076335230360445495,\n",
      "        3474635304423482980]), tensor([0, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 0, 0]), tensor([31244212048494684, 28429436511125606, 28710881422737503,\n",
      "        32651561162571873, 32370073300107356, 34058961815535732,\n",
      "        30399782823591982]), tensor([28429436511125606, 28710881422737503, 32651561162571873,\n",
      "        32370073300107356, 34058961815535732, 30399782823591982,\n",
      "        12666807751278697, 32088649863463018]), tensor([27303502244872303, 29555336417116211, 29555366481887330,\n",
      "        31525390671741044, 27303532308922465, 25896191785238631,\n",
      "        27866512327901300, 31525674138992744, 25896166015697012]), tensor([32370111954616435, 30962681236947036, 25896174606483567,\n",
      "        27866439313391681, 27303502244872303, 29555336417116211,\n",
      "        29555366481887330, 31525390671741044, 27303532308922465,\n",
      "        25896191785238631]), tensor([6586094347104288869,   32651616994721884,   29273822787141743,\n",
      "        5910511991600775263,   27303502243724411,   28147892814413940,\n",
      "          25896114476810337,   28429440805568622,   32088426523918451,\n",
      "          27866473672343649,   32651612702113838]), tensor([  25896174606483567,   30118316435898436,   25896178900992116,\n",
      "          29555366483132490, 6586094347104288869,   32651616994721884,\n",
      "          29273822787141743, 5910511991600775263,   27303502243724411,\n",
      "          28147892814413940,   25896114476810337,   28429440805568622]), tensor([27303502244872303, 29555336417116211, 29555366481887330,\n",
      "        31525390671741044, 27303532308922465, 25896191785238631,\n",
      "        27866512327901300, 29555302057377896, 29555362188492915,\n",
      "        29555370778493026, 25896191785828463, 27303536604020850,\n",
      "        26740552290861176]), tensor([27303502244872303, 29555336417116211, 29555366481887330,\n",
      "        31525390671741044, 27303532308922465, 25896191785238631,\n",
      "        27866512327901300, 29555302057377896, 29555362188492915,\n",
      "        29555370778493026, 25896191785828463, 29273891506028646,\n",
      "        30962741366882405, 27866456492605541]), tensor([32370111954616435, 30962681236947036, 25896174606483567,\n",
      "        27866439313391681, 27303502244872303, 29555336417116211,\n",
      "        29555366481887330, 31525390671741044, 27303532308922465,\n",
      "        25896191785238631, 27866512327901300, 27303493653758056,\n",
      "        30962681236881507, 30681167605989476, 26740517931581547]), tensor([29555366481887330, 31525390671741044, 27303532308922465,\n",
      "        25896191785238631, 27866512327901300, 27303493653758056,\n",
      "        30962681236881507, 26740517932040292, 27866542392737887,\n",
      "        28429419330863201, 26740517930729567, 29555345007902815,\n",
      "        12948256956809332, 32651616996819043, 12666846405656680,\n",
      "        31525394963628083]), tensor([29555366481887330, 31525390671741044, 27303532308922465,\n",
      "        25896191785238631, 27866512327901300, 30962719890604136,\n",
      "        28147974419578972, 32370056120500341, 31525605419712604,\n",
      "        27866439312670841, 26740530816024680, 32933010368036956,\n",
      "        29555370777313390, 12948342857138287, 32651616996819043,\n",
      "        12666846405656680, 31525394963628083])])\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "#所有英文字母加上五个标点符号(包含一个空格)\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "# 将unicode转为ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "#build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "# read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "import os\n",
    "file_path = r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\Pytorch_名字分类\\data\\data\\names'\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for idx, file in enumerate(files):\n",
    "        category = file.split('/')[-1].split('.')[0]\n",
    "        all_categories.append(category)\n",
    "        lines = readLines(os.path.join(root, file))\n",
    "        #category_lines[category] = lines\n",
    "        category_lines[torch.LongTensor(idx)] = lines\n",
    "n_categories = len(all_categories)\n",
    "print(category_lines.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   content category\n",
      "0        a        0\n",
      "1        a        1\n",
      "2        a        2\n",
      "3        a        3\n",
      "4        a        4\n",
      "5        a        5\n",
      "6        a        6\n",
      "7        a        7\n",
      "8        a        8\n",
      "9        a        9\n",
      "10       a       10\n",
      "11       a       11\n",
      "12       a       12\n",
      "13       a       13\n",
      "14       a       14\n",
      "15       a       15\n",
      "16       a       16\n",
      "17       a       17\n",
      "18       a       18\n",
      "19       a       19\n",
      "20       a       20\n",
      "21       a       21\n",
      "22       a       22\n",
      "23       a       23\n",
      "24       a       24\n",
      "25       a       25\n",
      "26       a       26\n",
      "27       a       27\n",
      "28       a       28\n",
      "29       a       29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_pd = pd.DataFrame(columns = ('content', 'category'))\n",
    "for i in range(30):\n",
    "    single = {'content': 'a', 'category': int(i)}\n",
    "    test_pd = test_pd.append(single, ignore_index = True)\n",
    "print(test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入为5类:\n",
      "torch.Size([1, 5])\n",
      "要计算loss的类别:\n",
      "torch.Size([1])\n",
      "计算loss的结果:\n",
      "tensor(3.3541, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(1, 5, requires_grad=True)\n",
    "target = torch.empty(1, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"输入为5类:\")\n",
    "print(input.size())\n",
    "print(\"要计算loss的类别:\")\n",
    "print(target.size())\n",
    "print(\"计算loss的结果:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "a = [1,2,3,4,5]\n",
    "print(randomChoice(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([100], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np_arr = np.array([100])\n",
    "tor_arr=torch.from_numpy(np_arr)\n",
    "print(tor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 64, 300])\n",
      "torch.Size([1, 64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 18])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "lstm_seq = nn.LSTM(300, 128, 1)\n",
    "lstm_input = Variable(torch.randn(19, 64, 300))\n",
    "out, (h, c) = lstm_seq(lstm_input)\n",
    "label = nn.Linear(128, 18)\n",
    "output = label(h[-1])\n",
    "print(lstm_input.shape)\n",
    "print(h.shape)\n",
    "print(h[-1].shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    " \n",
    "m = nn.Linear(20, 18)\n",
    "input = torch.randn(64, 20)\n",
    "output = m(input)\n",
    " \n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "0    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.Series([1,2,3,4,5])\n",
    "print(test)\n",
    "print(test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "0  1  3\n",
      "1  2  4\n",
      "Index(['a', 'b'], dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [a, b]\n",
      "Index: []\n",
      "Series([], Name: a, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame({'a':[1,2], 'b':[3,4]})\n",
    "Columns = test.columns\n",
    "print(test)\n",
    "print(Columns)\n",
    "# print(\"-----\")\n",
    "test = pd.DataFrame(columns = Columns)\n",
    "print(test)\n",
    "print(test['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'a'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b7aed3375a52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'a'"
     ]
    }
   ],
   "source": [
    "test1 = pd.DataFrame()\n",
    "print(test1)\n",
    "print(test1['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "lista=[1,-2,0,-4,-5]\n",
    "listb=[a for a in lista if a<0]\n",
    "print(len(listb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,12):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 33, 24])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "input = Variable(torch.randn(30, 16, 50))\n",
    "m = nn.Conv1d(16, 33, 3, stride = 2)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
