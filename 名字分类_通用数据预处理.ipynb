{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名字中最长长度为19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.iterator.BucketIterator object at 0x000001656E291278>\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from torchtext import data\n",
    "from tqdm import tqdm\n",
    "from torch.nn import init\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "#所有英文字母加上五个标点符号(包含一个空格)\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "# 将unicode转为ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "#build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "# read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "file_path = r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\Pytorch_名字分类\\data\\data\\names'\n",
    "#数据整合成dataframe\n",
    "total_data = pd.DataFrame(columns = ('content', 'category'))\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for idx, file in enumerate(files):\n",
    "        category = file.split('/')[-1].split('.')[0]\n",
    "        all_categories.append(category)\n",
    "        lines = readLines(os.path.join(root, file))\n",
    "        for line in lines:\n",
    "            single_name = {'content':line, 'category':int(idx)}\n",
    "            total_data = total_data.append(single_name, ignore_index = True)\n",
    "#找到最长名字，做pad用(fix_length = 最长长度)\n",
    "max_length = 0\n",
    "for i in total_data['content']:\n",
    "    if len(i) > max_length:\n",
    "        max_length = len(i)\n",
    "print('名字中最长长度为%d'%max_length)\n",
    "#解决loss值不变的方法一：打乱数据集(total_data)\n",
    "total_data = shuffle(total_data)\n",
    "tokenize = lambda x: x.split()\n",
    "#data.Field:定义样本的处理操作\n",
    "TEXT = data.Field(sequential = True, tokenize = tokenize, lower = True, fix_length = 19)\n",
    "LABEL = data.Field(sequential = False, use_vocab = False)\n",
    "#将原始的corpus转换成data.Example实例(主要为data.Example.fromlist方法)\n",
    "#都是train数据，就不用区分是train还是test了\n",
    "def get_dataset(content_info, category_info, text_field, label_field):\n",
    "    fields = [('content', text_field),\n",
    "               ('category', label_field)]\n",
    "    examples = []\n",
    "    for text, label in zip(content_info, category_info):\n",
    "        examples.append(data.Example.fromlist([text, label], fields))\n",
    "    return examples, fields\n",
    "train_examples, train_fields = get_dataset(total_data['content'], total_data['category'],\n",
    "                                          TEXT, LABEL)\n",
    "#使用torchtext.data.Dataset来构建数据集\n",
    "train = data.Dataset(train_examples, train_fields)\n",
    "TEXT.build_vocab(train)\n",
    "weight_matrix = TEXT.vocab.vectors\n",
    "#解决loss值不变的方法二：减小batch_size\n",
    "train_iter = BucketIterator(train, batch_size = 50, device = -1,\n",
    "                            sort_key = lambda x: len(x.content),\n",
    "                            sort = False,sort_within_batch = False, repeat = False)\n",
    "print(train_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
