{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors\n",
    "from torch.nn import init\n",
    "from tqdm import tqdm\n",
    "tokenize = lambda x: x.split()\n",
    "#data.Field:定义样本的处理操作\n",
    "TEXT = data.Field(sequential = True, tokenize = tokenize, lower = True, fix_length = 200)\n",
    "LABEL = data.Field(sequential = False, use_vocab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将原始的corpus转换成data.Example实例(主要为data.Example.fromlist方法)\n",
    "def get_dataset(csv_data, text_field, label_field, test=False):\n",
    "    fields = [('id', None), ('comment_text', text_field), ('toxic', label_field)]\n",
    "    examples = []\n",
    "    if test:\n",
    "        #如果为测试集，则不加载label\n",
    "        for text in tqdm(csv_data['comment_text']):\n",
    "            examples.append(data.Example.fromlist([None, text, None], fields))\n",
    "    else:\n",
    "        for text, label in tqdm(zip(csv_data['comment_text'], csv_data['toxic'])):\n",
    "            examples.append(data.Example.fromlist([None, text, label], fields))\n",
    "    return examples, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:00, 35.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 87.79it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [00:00, 182.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 169.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 33/33 [00:00<00:00, 8261.43it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\train.csv', engine='python')\n",
    "test_data = pd.read_csv(r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\test.csv', engine='python')\n",
    "valid_data = pd.read_csv(r'C:\\Users\\lenovo\\Desktop\\Josie\\自学\\TorchText\\practical-torchtext-master\\practical-torchtext-master\\data\\valid.csv', engine='python')\n",
    "#得到构建Dataset所需的examples和fields\n",
    "train_examples, train_fields = get_dataset(train_data, TEXT, LABEL)\n",
    "valid_examples, valid_fields = get_dataset(valid_data, TEXT, LABEL)\n",
    "test_examples, test_fields = get_dataset(test_data, TEXT, None, test=True)\n",
    "#使用torchtext.data.Dataset来构建数据集\n",
    "train = data.Dataset(train_examples, train_fields)\n",
    "valid = data.Dataset(valid_examples, valid_fields)\n",
    "test = data.Dataset(test_examples, test_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对比于旧代码，旧代码在这里报错，可能是不能调用GLOVE\n",
    "#旧代码\n",
    "# vectors = Vectors(name='myvector/glove/glove.6B.200d.txt', cache=cache)\n",
    "# TEXT.build_vocab(train, vectors=vectors)\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from torchtext import data\n",
    "TEXT.build_vocab(train)\n",
    "weight_matrix = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "        (train, valid), # 构建数据集所需的数据集\n",
    "        batch_sizes=(8, 8),\n",
    "        # 如果使用gpu，此处将-1更换为GPU的编号\n",
    "        device=-1,\n",
    "        # the BucketIterator needs to be told what function it should use to group the data.\n",
    "        sort_key=lambda x: len(x.comment_text),\n",
    "        sort_within_batch=False,\n",
    "        repeat=False\n",
    ")\n",
    "test_iter = Iterator(test, batch_size=8, device=-1, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 8]) torch.Size([8])\n",
      "torch.Size([200, 8]) torch.Size([8])\n",
      "torch.Size([200, 8]) torch.Size([8])\n",
      "torch.Size([200, 1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_iter):\n",
    "    text, label = batch.comment_text, batch.toxic\n",
    "    print(text.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 8, 300])\n",
      "torch.Size([200, 8, 128])\n",
      "tensor(0.8237, grad_fn=<NllLossBackward>)\n",
      "torch.Size([200, 8, 300])\n",
      "torch.Size([200, 8, 128])\n",
      "tensor(0.5778, grad_fn=<NllLossBackward>)\n",
      "torch.Size([200, 8, 300])\n",
      "torch.Size([200, 8, 128])\n",
      "tensor(0.5465, grad_fn=<NllLossBackward>)\n",
      "torch.Size([200, 1, 300])\n",
      "torch.Size([200, 1, 128])\n",
      "tensor(0.6153, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "weight_matrix = TEXT.vocab.vectors\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(len(TEXT.vocab), 300)  # embedding之后的shape: torch.Size([200, 8, 300])\n",
    "        # 若使用预训练的词向量，需在此处指定预训练的权重\n",
    "        # embedding.weight.data.copy_(weight_matrix)\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=1)  # torch.Size([200, 8, 128])\n",
    "        self.decoder = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        print(embeds.shape)\n",
    "        lstm_out = self.lstm(embeds)[0]  # lstm_out:200x8x128\n",
    "        print(lstm_out.shape)\n",
    "        # 取最后一个时间步\n",
    "        final = lstm_out[-1]  # 8*128\n",
    "        y = self.decoder(final)  # 8*2 \n",
    "        return y\n",
    "\n",
    "def main():\n",
    "    model = LSTM()\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "    loss_funtion = F.cross_entropy\n",
    "    for epoch, batch in enumerate(val_iter):\n",
    "        optimizer.zero_grad()\n",
    "        start = time.time()\n",
    "        predicted = model(batch.comment_text)\n",
    "        loss = loss_funtion(predicted, batch.toxic)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------我是昏割线------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "packed: PackedSequence(data=tensor([[1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.]]), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import utils as nn_utils\n",
    "\n",
    "batch_size = 2\n",
    "max_length = 3\n",
    "hidden_size = 2\n",
    "n_layers = 1\n",
    "tensor_in = torch.FloatTensor([[1,2,3], [1,0,0]]).resize_(2,3,1)\n",
    "tensor_in = Variable(tensor_in)\n",
    "seq_lengths = [3,1]\n",
    "pack = nn_utils.rnn.pack_padded_sequence(tensor_in, seq_lengths, batch_first = True)\n",
    "print(tensor_in.size())\n",
    "print('packed:', pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.]]), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "torch.Size([1, 2, 2])\n",
      "PackedSequence(data=tensor([[ 0.3417,  0.1451],\n",
      "        [ 0.4003, -0.0267],\n",
      "        [ 0.6926,  0.0129],\n",
      "        [ 0.8593, -0.0580]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(1, hidden_size, n_layers, batch_first = True)\n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "out,_ = rnn(pack,h0)\n",
    "\n",
    "print(pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.3804, 0.3318],\n",
      "         [0.2580, 0.8287]],\n",
      "\n",
      "        [[0.8048, 0.7970],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.9553, 0.8879],\n",
      "         [0.0000, 0.0000]]], grad_fn=<CopySlices>), tensor([3, 1]))\n"
     ]
    }
   ],
   "source": [
    "unpacked = nn_utils.rnn.pad_packed_sequence(out)\n",
    "print(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(([0, 1, 2], [3, 4], [5, 6, 7, 8]), 1)\n",
      "tensor([[0., 1., 2., 0.],\n",
      "        [3., 4., 0., 0.],\n",
      "        [5., 6., 7., 8.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#序列填充(可用)\n",
    "\n",
    "a = (([0,1,2], [3,4], [5,6,7,8]), 1)\n",
    "print(a)\n",
    "# store length of each element in an array\n",
    "len_a = np.array([len(a) for a in a[0]]) \n",
    "variable_a  = np.zeros((len(len_a), np.amax(len_a)))\n",
    "for i, a in enumerate(a[0]):\n",
    "    variable_a[i, 0:len(a)] = a\n",
    " \n",
    "vocab_size = len(np.unique(variable_a))\n",
    "variable_a = Variable(torch.from_numpy(variable_a))\n",
    "print(variable_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    " \n",
    "    def __init__(self, input_size, emsize):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emsize)\n",
    " \n",
    "    def forward(self, input_variable):\n",
    "        return self.embedding(input_variable)\n",
    " \n",
    " \n",
    "class Encoder(nn.Module):\n",
    " \n",
    "    def __init__(self, input_size, hidden_size, bidirection):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirection = bidirection\n",
    "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, batch_first=True, \n",
    "                                    bidirectional=self.bidirection)\n",
    " \n",
    "    def forward(self, sent_variable, sent_len):\n",
    "        # Sort by length (keep idx)\n",
    "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
    "        idx_unsort = np.argsort(idx_sort)\n",
    " \n",
    "        idx_sort = torch.from_numpy(idx_sort)\n",
    "        sent_variable = sent_variable.index_select(0, Variable(idx_sort))\n",
    " \n",
    "        # Handling padding in Recurrent Networks\n",
    "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent_variable, sent_len, batch_first=True)\n",
    "        sent_output = self.rnn(sent_packed)[0]\n",
    "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output, batch_first=True)[0]\n",
    " \n",
    "        # Un-sort by length\n",
    "        idx_unsort = torch.from_numpy(idx_unsort)\n",
    "        sent_output = sent_output.index_select(0, Variable(idx_unsort))\n",
    " \n",
    "        return sent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = EmbeddingLayer(vocab_size, 50)\n",
    "enc = Encoder(50, 100, False, 'LSTM')\n",
    " \n",
    "emb_a = emb(variable_a)\n",
    "enc_a = enc(emb_a, len_a)\n",
    "print(enc_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
